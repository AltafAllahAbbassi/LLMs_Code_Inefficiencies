Timestamp,Email,What programming language do you use most frequently?,Have you used LLM models to assist you writing code? ,What LLM models do you usually use ?,What issues have you encountered in the LLM generated code?,"What is your current job title? For students, please indicate your degree: Master's, PhD, etc.",What is your coding experience?,"How often do you encounter Wrong Logic inefficiencies in LLM-generated code?

All scores are given on a scale from 1 to 5, where 1 indicates a rare occurrence and 5 indicates a frequent occurrence.","To Which extent Wrong Logic is relevant to be considered?
 
All scores are given on a scale from 1 to 5, with 1 indicates low importance and 5 indicates high importance.
","Do you have any additional comment, feedback or suggestion regarding Wrong Logic?  ","How often do you encounter Partially Wrong Logic inefficiencies in LLM-generated code?

All scores are given on a scale from 1 to 5, where 1 indicates a rare occurrence and 5 indicates a frequent occurrence.","To Which extent Partially Wrong Logic is relevant to be considered?
 
All scores are given on a scale from 1 to 5, with 1 indicates low importance and 5 indicates high importance.","Do you have any additional comment, feedback or suggestion regarding Partially Wrong Logic?  ","How often do you encounter Wrong Method Input inefficiencies in LLM-generated code?

All scores are given on a scale from 1 to 5, where 1 indicates a rare occurrence and 5 indicates a frequent occurrence.","To Which extent Wrong Method Input is relevant to be considered?
 
All scores are given on a scale from 1 to 5, with 1 indicates low importance and 5 indicates high importance.","Do you have any additional comment, feedback or suggestion regarding Wrong Method Input?  ","To Which extent General Logic is relevant to be considered?
 
All scores are given on a scale from 1 to 5, with 1 indicates low importance and 5 indicates high importance.",Have you encountered other inefficiencies in the General Logic category that you believe have not been mentioned?,"How often do you encounter Sub-Optimal Solution (Memory) inefficiencies in LLM-generated code?

All scores are given on a scale from 1 to 5, where 1 indicates a rare occurrence and 5 indicates a frequent occurrence.","To Which extent Sub-Optimal Solution (Memory) is relevant to be considered? 

All scores are given on a scale from 1 to 5, with 1 indicates low importance and 5 indicates high importance.","Do you have any additional comment, feedback or suggestion regarding Sub-Optimal Solution (Memory)?  ","How often do you encounter Sub-Optimal Time Complexity Solution inefficiencies in LLM-generated code?

All scores are given on a scale from 1 to 5, where 1 indicates a rare occurrence and 5 indicates a frequent occurrence.","To Which extent Sub-Optimal Time Complexity Solution is relevant to be considered? 

All scores are given on a scale from 1 to 5, with 1 indicates low importance and 5 indicates high importance.

","Do you have any additional comment, feedback or suggestion regarding Sub-Optimal Time Complexity Solution?","How often do you encounter Unnecessary Steps inefficiencies in LLM-generated code?

All scores are given on a scale from 1 to 5, where 1 indicates a rare occurrence and 5 indicates a frequent occurrence.","To Which extent Unnecessary Steps is relevant to be considered?
 
All scores are given on a scale from 1 to 5, with 1 indicates low importance and 5 indicates high importance.","Do you have any additional comment, feedback or suggestion regarding Unnecessary Steps?","How often do you encounter Redundant Steps inefficiencies in LLM-generated code?

All scores are given on a scale from 1 to 5, where 1 indicates a rare occurrence and 5 indicates a frequent occurrence.","To Which extent Redundant Steps is relevant to be considered?
 
All scores are given on a scale from 1 to 5, with 1 indicates low importance and 5 indicates high importance.","Do you have any additional comment, feedback or suggestion regarding Redundant Steps?  ","How often do you encounter Inefficient Repetitive Block inefficiencies in LLM-generated code?

All scores are given on a scale from 1 to 5, where 1 indicates a rare occurrence and 5 indicates a frequent occurrence.","To Which extent Inefficient Repetitive Block is relevant to be considered? 

All scores are given on a scale from 1 to 5, with 1 indicates low importance and 5 indicates high importance.","Do you have any additional comment, feedback or suggestion regarding Inefficient Repetitive Block?  ","To Which extent Performance is relevant to be considered?
  
All scores are given on a scale from 1 to 5, with 1 indicates low importance and 5 indicates high importance.",Have you encountered other inefficiencies in the Performance category that you believe have not been mentioned?,"How often do you encounter Confusing Naming inefficiencies in LLM-generated code?

All scores are given on a scale from 1 to 5, where 1 indicates a rare occurrence and 5 indicates a frequent occurrence.","To which extent Confusing Naming is relevant to be considered?
 
All scores are given on a scale from 1 to 5, with 1 indicates low importance and 5 indicates high importance.","Do you have any additional comment, feedback or suggestion regarding Confusing Naming?  ","How often do you encounter Sub-Readable Code Exists inefficiencies in LLM-generated code?

All scores are given on a scale from 1 to 5, where 1 indicates a rare occurrence and 5 indicates a frequent occurrence.

 ","To Which extent Sub-Readable Code Exists is relevant to be considered?
 
All scores are given on a scale from 1 to 5, with 1 indicates low importance and 5 indicates high importance.","Do you have any additional comment, feedback or suggestion regarding Sub-Readable Code Exists?  ","To which extent Readability is relevant to be considered?
 
All scores are given on a scale from 1 to 5, with 1 indicates low importance and 5 indicates high importance.",Have you encountered other inefficiencies in the Readability category that you believe have not been mentioned?,"How often do you encounter Code Duplication inefficiencies in LLM-generated code?

All scores are given on a scale from 1 to 5, where 1 indicates a rare occurrence and 5 indicates a frequent occurrence.","To which extent Code Duplication is relevant to be considered?
 
All scores are given on a scale from 1 to 5, with 1 indicates low importance and 5 indicates high importance.","Do you have any additional comment, feedback or suggestion regarding Code Duplication?  ","How often do you encounter Comment Duplication inefficiencies in LLM-generated code?

All scores are given on a scale from 1 to 5, where 1 indicates a rare occurrence and 5 indicates a frequent occurrence.","To which extent Comment Duplication is relevant to be considered?
 
All scores are given on a scale from 1 to 5, with 1 indicates low importance and 5 indicates high importance.","Do you have any additional comment, feedback or suggestion regarding Comment Duplication?  ","How often do you encounter Unnecessary Conditional Block inefficiencies in LLM-generated code?

All scores are given on a scale from 1 to 5, where 1 indicates a rare occurrence and 5 indicates a frequent occurrence.
","To which extent Unnecessary Conditional Block is relevant to be considered? 

All scores are given on a scale from 1 to 5, with 1 indicates low importance and 5 indicates high importance.","Do you have any additional comment, feedback or suggestion regarding Unnecessary Conditional Block?  ","How often do you encounter Unnecessary Else inefficiencies in LLM-generated code?

All scores are given on a scale from 1 to 5, where 1 indicates a rare occurrence and 5 indicates a frequent occurrence.","To which extent Unnecessary Else is relevant to be considered?
 
All scores are given on a scale from 1 to 5, with 1 indicates low importance and 5 indicates high importance.","Do you have any additional comment, feedback or suggestion regarding Unnecessary Else Statement?  ","To which extent Maintainability is relevant to be considered?
 
All scores are given on a scale from 1 to 5, with 1 indicates low importance and 5 indicates high importance.",Have you encountered other inefficiencies in the Maintainability  category that you believe have not been mentioned?,"How often do you encounter Missing Import inefficiencies in LLM-generated code?

All scores are given on a scale from 1 to 5, where 1 indicates a rare occurrence and 5 indicates a frequent occurrence.","To which extent Missing Import is relevant to be considered?
 
All scores are given on a scale from 1 to 5, with 1 indicates low importance and 5 indicates high importance.","Do you have any additional comment, feedback or suggestion regarding Missing Import?  ","How often do you encounter Missing Variable Declaration inefficiencies in LLM-generated code?

All scores are given on a scale from 1 to 5, where 1 indicates a rare occurrence and 5 indicates a frequent occurrence.","To which extent Missing Variable Declaration is relevant to be considered? 

All scores are given on a scale from 1 to 5, with 1 indicates low importance and 5 indicates high importance.","Do you have any additional comment, feedback or suggestion regarding Missing Variable Declaration?  ","How often do you encounter Syntax Error inefficiencies in LLM-generated code?

All scores are given on a scale from 1 to 5, where 1 indicates a rare occurrence and 5 indicates a frequent occurrence.","To which extent Syntax Error is relevant to be considered?
 
All scores are given on a scale from 1 to 5, with 1 indicates low importance and 5 indicates high importance.","Do you have any additional comment, feedback or suggestion regarding Syntax Error? ","To which extent Error is relevant to be considered?
 
All scores are given on a scale from 1 to 5, with 1 indicates low importance and 5 indicates high importance.",Have you encountered other inefficiencies in the Error  category that you believe have not been mentioned?,"Do you believe you encountered any other inefficiencies that were not mentioned? If yes, please provide them in the text below."
12/17/2024 18:06:31,,"Python, C/C++",Yes,"ChatGPT, Claude","When using LLM code generation for debugging, the LLM will often fix the bug but introduce new bugs or unwanted features into the code. The changes introduced are often unwanted, even though they are an attempt to improve the code further than specified in the prompt. When making multiple edits with software like Devin or Windsurf, i often need to use git to make sure that I can quickly undo edits.",Machine Learning Engineer,1-3 years,1,1,,3,3,,5,4,,3,,2,2,,3,1,,4,2,,3,1,,1,1,,4,,1,1,,1,1,,5,,1,1,,1,1,,3,2,,1,1,,5,,5,5,,3,3,,1,2,,3,,
12/17/2024 18:09:47,,Python,Yes,"Copilot, ChatGPT, Mistral","It basically guesses at what the code should be based on the lexicon or comments or input. It doesn’t use the proper libraries or function methods for calling the right code bits. If making a very basic code then it can maybe do a passable job, but if anything more complicated than a calculator then it struggles.",Cyber Security consultant ,More than 5 years,4,5,It depends on the model used as well ,4,5,It can be misleading unless the code is reviewed by a senior programmer able to identify these issues. A junior coder who uses this could cause issues if pushed to production code without proper review ,5,5,The correct method call for the function we are trying to implement is important ,4,,3,3,,3,4,,3,3,,3,3,,3,3,Can be handled better with object oriented code implementation ,3,I stopped using llm generated code because it simply didn’t work enough for me to get to this point ,2,4,,2,4,,2,,3,3,,2,3,,3,2,,1,2,,2,,4,2,Sometimes imports things that doesn’t exist,3,3,,3,4,Depends on python version as well,3,,Handling corner cases or error handling is not comprehensive 
12/17/2024 19:12:17,,Python,No,"ChatGPT, Gimini","odd formatting, newlines in mixed format, reference to api that doesn't exist",High School ,More than 5 years,3,5,,3,5,,1,5,,4,,5,3,,3,4,,4,2,,5,5,,3,4,,5,,1,1,,1,1,,1,,3,3,,1,1,,5,2,,4,3,,5,,3,2,,3,3,,1,3,,4,,
12/17/2024 19:30:09,,"Python, C/C++, Verilog, Scala",Yes,Claude,"Incorrect code, weird/unoptimize way of doing things, poor performance in certain domain like HDL",Master student,More than 5 years,2,5,,5,5,,5,5,One of the biggest issue,5,,4,3,,4,4,,3,1,"Generally if the thing does nothing and it's a compiled language, it will get eliminated by dead code elimination by the compiler",1,3,,4,4,,4,,5,4,"Always like to rename stuff when doing new version, things like that",3,4,,4,,3,3,,3,1,"With copilot it was happening a lot, with Claude I pretty much never had this issue",3,1,,2,1,,3,,5,2,"Annoying to ask again, but not horrible",3,5,A bit more annoying,3,3,,4,,
12/17/2024 19:54:32,,"Python, C/C++",Yes,"ChatGPT, Gimini","Cannot support large enough context - the problem should be significantly simplified before prompted to the LLM, which often leads to ineffective solutions.
Even in Python, only the standard library and some most wide-used modules, i.e. numpy, are ""known"" by LLMs well enough to trust their responses. When dealing with things like tkinter and less popular libraries, a huge amount of mistakes and hallutinations comes up.
Will lie you in the face if their knowledge on the subject is limited and come up with completely wrong code, even if prompted to say ""I don't know how to do this"" in these situations.
2-3 responses, and you have to start a new chat to get rid of hallutinations.
Overall, they can give a general idea for a solution or be used as ""smarter google"", but the code itself must be triple-checked and, preferably, completely rewritten by the programmer to ensure its safety, efficiency and, well, ability to even be executed. ",Bachelor’s degree,3-5 years,1,3,"It's not really a thing, at least not with gpt4. It will more likely generate an unworking code which, though, will look plausible and following the intended logic.
Even if the situation from the example occurs, it'll be easy for the programmer to tell that this code isn't what they wanted at all, so the importance of this problem shouldn't be really high. ",3,4,"Can and does happen, especially if the logic isn't related to the main idea of the algorithm. Can be easy to miss by the programmer as well. ",5,5,,5,,3,3,,4,2,"Mostly depends on the prompt. If you tell LLM to generate a more effective solution, it will. Will it be correct, however...",2,2,,4,3,,5,4,,5,,1,1,"At least in the context of Python, it isn't a thing with modern LLMs. ",3,4,,3,,2,2,,1,1,"Afaik, it can happen with Copilot; however, I've never used it, and other LLMs don't seem to struggle with this issue. It's more like a flaw of one particular LLM. ",2,2,,2,1,,4,The more larger problem with maintainability of the AI generated code is that it tends to write a solution for one specific problem, even the smallest further changes in the way this peace of code is intended to use often leads to the situation when you need to rewrite it from scratch.,1,1,"Unless you prompt the LLM to generate an entire file of code, it shouldn't be a problem for anyone with at least basic coding experience.",1,1,,1,1,,5,"Using inexistent library functions and methods, incorrectly used ones that do exist. "
12/17/2024 20:33:22,,Python,Yes,"ChatGPT, DeepSeek",debug,PhD,More than 5 years,4,4,,3,3,,3,4,,4,no,3,3,,3,2,,3,2,,3,3,,3,4,,3,no,4,5,,4,4,,5,no,2,2,,5,5,,3,3,,3,3,,3,,5,5,,4,4,,3,3,,5,,Your summary is very comprehensive!I have nothing more to add.
12/17/2024 21:25:25,,"Python, JavaScript",Yes,"Copilot, ChatGPT","Not sure if I'd call it an issue, it doesn't suggest the correct code every once in a while even if given comments and a lot of context in the same file. Guess it's an expected limitation.",Senior Frontend Engineer,More than 5 years,2,5,,3,4,,4,3,,4,,4,2,I believe this is the part where the dev using the LLM has to step in and optimize the code generated by the LLM. My impression is that by no means is LLM generated code expected to be shipped as is.,3,2,,4,2,,4,2,,4,1,,2,,4,2,"Like the previous issue (regarding performance and efficiency), this is where stepping in as a dev matters. I don't think it's an issue because I have to review the code and I can ask the LLM to revise and make it better or I can improve it myself.
I still save time compared to having to write it from scratch.",4,2,,1,,4,3,,4,2,,3,2,,4,1,,1,,4,3,,3,4,,3,5,This is especially egregious if a dev is using an LLM to speed up learning a new language,4,,
12/17/2024 22:39:29,,Python,Yes,ChatGPT,Performs poorly when the context is vague.,Mlops Specialist,More than 5 years,1,4,,4,5,,2,2,,4,,5,5,Improving the prompt could solve this problem.,5,5,,5,5,,1,3,,1,3,,5,,1,1,,1,1,The code is often well writen,1,,2,3,,1,1,,2,3,,2,3,,3,,4,5,,4,5,,2,5,,5,,"Any inefficiencies related to lengthy prompts with a lot of context: halucination, suboptimat response, partial response, ..."
12/17/2024 22:49:33,,"Python, C/C++",Yes,"ChatGPT, Claude","The most common issue I encounter with chat-based LLMs (Claude, ChatGPT) are hallucinations. Coding assistants (GitHub Copilot, Cursor) have their own set of additional issues like getting in the way while programming, and I gave up on them entirely for now.",Master's,More than 5 years,1,3,,2,3,,2,3,,2,I don't encounter this issue a lot. I think good prompts strongly mitigate this type of errors.,4,4,,3,4,,3,3,,2,3,,2,4,,3,,2,2,,1,1,,1,,1,1,"I don't prompt LLMs to generate large enough chunks of code at once for this to be an issue. Maybe it would be an issue with ai agent like Devin, put in charge of larger tasks.",1,1,,2,1,,3,1,"I'm not sure there is a strong consensus on unnecessary else statements being an issue, it's a style decision which can vary between programming communities.",1,,2,3,,2,4,,3,4,"Not so much an issue with Python which has a simple syntax (although I did get whitespace issues with LLMs in the past) and lots of code available, but syntax errors become more common with more complex/rare languages.",5,"In Python I get a lot of errors when using lesser known libraries, like LLMs hallucinating functions that do not actually exist in the library.",
12/17/2024 23:35:47,,Python,Yes,"Copilot, ChatGPT, Gimini, Claude",logical errors,"Software Engineer, Bachelor",More than 5 years,2,1,Feedback from Critique LLM will solve this.,1,1,Testing LLM would solve this.,1,1,"https://chatgpt.com/share/676246d4-0ca0-8010-aa09-dbceaefded91
Need model info.",5,No,1,5,Clear prompting would help,1,5,Clear prompting would help,2,5,Feedback from Critique LLM will help,1,5,Feedback from Critique LLM will help,1,5,Feedback from Critique LLM will help,5,No,1,5,Wrong function name? https://chatgpt.com/share/6762492b-a9f4-8010-96e1-0b5f066b69a4,1,1,"Spanning the same over multiple lines will make them easily readable.
[Are list-comprehensions and functional functions faster than ""for loops""?](https://stackoverflow.com/a/22108640)",5,No,1,5,Proper prompting,4,5,Happens in Cursor,1,5,Better Prompting will help,1,5,[It is more efficient to use if-return-return or if-else-return?](https://stackoverflow.com/a/9191474) - I prefer without else,5,No,1,5,Linting would help,1,5,Linting would help,1,5,Not seen yet. Linting would help,5,No,"Hallucination, repetition."
12/18/2024 4:03:21,,Python,Yes,ChatGPT,Lacks visibility on the other files and scripts I have,Ai engineer,1-3 years,2,4,,4,4,,1,5,,5,,4,4,,4,4,,3,4,,2,5,,3,4,,2,,1,1,,3,2,,1,,3,2,,1,1,,2,2,,2,2,,3,,4,5,,3,5,,2,4,,2,,
12/18/2024 7:53:31,,JavaScript,Yes,"Copilot, ChatGPT",For me it's been pleasure to use LLMs. My problems may be more related to UX or other systems around LLMs. Sometimes IDE doesn't generate code when I want it to. With ChatGPT I've experienced different quality outputs for similar first prompts. Also if you ask solution for bigger problems that should be splitted into separate prompts.,Manager and part-time teacher,More than 5 years,1,2,,2,2,"Yes, I've seen Partially Wrong Logic and Wrong Logic mostly on open-source, free or less known models. I've tried running 40gb sized models with billions of parameters locally and it produces ""garbage"" most of the time. I've experienced them rarely with paid Copilot and ChatGPT 3.5 and newer o4.",1,3,,2,,3,2,,3,2,,3,3,,1,2,,1,1,Probably depends a lot on input prompt.,2,"It's rare but it happens, in ChatGPT you can mention performance problems and it can find the problem on its own. In Copilot I've asked to generate alternative code when examples.",1,1,,4,1,"It happens, but if it works I don't care. And you can ask model to explain that code.",1,,2,1,It happens mostly on Copilot when generating line-by-line and doing manual changes.,3,3,I feel it is better nowadays.,2,3,,2,3,,3,,2,1,It's easy to fix when reading error output.,1,1,Never experienced,1,1,,1,,"Not exactly new inefficiencies, but I've experienced that compiled languages like C# gets worse results with Copilot than interpreted languages like JS, Python and PHP. Probably less quality training data available."
12/18/2024 11:32:03,,Python,Yes,"Copilot, ChatGPT",using deprecated modules/libraries (python),PhD,More than 5 years,2,4,,3,4,,1,3,,5,,3,4,,1,4,,1,2,,1,2,,1,4,,4,,1,3,,4,3,,5,,5,4,,5,1,,1,2,,4,3,,3,,2,5,,1,4,,1,1,,5,,
12/18/2024 11:47:31,,"Python, Java, JavaScript, C/C++",Yes,"Copilot, ChatGPT, Gimini","Most of the time, they give wrong code or poor optimized code. Sometimes, they gave 3/4 same codes randomly each time.","Instructor (Lecturer), United International University",More than 5 years,2,3,"It happens most for the newer tech stacks/frameworks/tools, etc.",4,5,"Before ending the output, the LLM should conduct a self-check to test whether the complete solution is in its output token or something is still missing.",3,4,It happens mostly if the user himself fails to use good prompts.,5,"Optimization plays a significant role here, to be honest, where the LLMs are still lacking too much currently.",4,5,"The LLMs should have a specific parameter as time-space complexity constraints. If it can be trained well by the given contraints criteria, then I do beileve it can be improved a lot.",3,5,,4,5,,4,4,,3,4,,5,,4,5,,4,5,,4,,4,2,,1,1,,2,5,,3,2,,5,,3,4,,2,5,,2,4,,2,,
12/18/2024 11:59:39,,Python,Yes,ChatGPT,"The most common is oversimplification to the point of uselessness. Say you ask it to help you writing a flask app where a background process splits up an audio file based, say, two different speakers. It will sometimes write the entire structure of the frontend/backend support for flask, but then just have a '# todo: implement a background job that performs file splitting' - thereby 'skipping' the part of the answer that was actually desired. When pressed, it may provide a satisfactory answer, or it may continue to provide 'avoidant' answers, such as providing a solution to splitting the audio file based on an arbitrarily easier task, such as 'for now, lets split the file every 10s, as a placeholder for splitting the file based on different speakers'

(this is a bad example, as file splitting is likely routine enough it would provide the function - but imagine a more novel or specific use case)

Frankly - the typical response from the llm far surpasses my expectations - but it does occasionally provide these avoidant answers. Other occasional issues:
* Suggests non-existent library/API
* Uses a lesser-known library/API, and hallucinates the endpoint it needs to exist (e.g., hallucinating a 'split mp3 on different speakers' library method - as a way of simplifying the question. It is, occasionally, confidently incorrect here, and will insist that the non-existent method should be used. Normally, however, when confronted, it agrees and tries a new solution.
* It performs more like a novice coder with certain 'problem spaces'. In particular, it seems to provide much sloppier, less robust, less readable answers when it is ""helping you develop a game"" (rather than, say, when designing system architecture) - even if the logic behind the answer could be the same, just the 'set dressing' is different. This makes sense, of course, as the quality of the LLMs input data would vary wildly depending on the online human community's skill level discussing the issue - (anecdotally) game dev is much more comfortable with naive, sloppy solutions.","Dev Ops, Software Developer and AI Engineer",More than 5 years,1,5,,2,5,,1,4,,5,,3,1,"When educating human coding students, I discourage worrying about time and memory constrains (perhaps more than university professors). In industry, writing bug-free and readable code is 1000x more important than efficient code - as bug-fighting is a constant war that you wage with every line of code, but requirements for memory/speed are actually rare-er than you think, and you normally see them coming. I.e.: I think developers should:
* Write everything maximizing agility and readability, ignoring memory and speed entirely
* Once you encounter a place where speed / memory run out, then go back, profile and benchmark, and rewrite the most critical code

I find that chat-gpt 'matches my ethos' in this regard, where it provides inefficient solutions, but you can specifically request it go back and add in benchmarks. Then, you report which sections of code are slowest, and it will attempt to rewrite those sections to optimize>
(Though, llms are less-good at the (imho) 'best type' of optimization - which is just find a way to relax your constraints or do less. It usually prefers to find 'code-review' solutions to optimization that involve list juggling - whereas, irl, I almost always just find a way to cache or memoize or limit the input data, rather than worrying the fiddly details)",4,1,,5,2,"This is occasionally more important because it makes the answer less readable. I am less concerned with the performance, but do believe good answers should be simple so that they are easy for humans to parse.",2,2,,2,2,"Similarly, I find this more important because it impacts readability.",1,,1,2,"I actually find that it is more clear and verbose than I would normally be. And I definitely prefer it err on the side of long var names, rather than short>
The only time I find it offers confusing names is when the problem space is sufficiently confusing and the language-parsing of homonyms or related words is what fails, rather than using short or shadowed code words.
E.g.:
If writing software that draws music notion, when drawing the ""ledger lines"" it might call them ""staffs"" in code. So it solves the problem correctly, and uses variable names that are properly self explanatory and would be good names - but are highly confusing to us humans as it is using incorrect terminology,",3,4,,2,,2,1,"More often, it will simply choose to use a similar loop twice rather than try to abstract it to be more perfectly 'dry'. However, I normally agree with it's duplication, as some 'wetness' is a good sacrifice for readability (as abstraction can make problems far less readable, in some cases).
So the 'issue' stems from the fact that I normally provide an example or two to the AI, and it implements the solution with duplication, not knowing abstraction is mandatory as the real problem set has hundreds of examples. Sometimes, even when the llm is informed that there are hundreds of examples, it will write '# TODO duplicate loop for the other types'. However, normally, if you request abstraction, it will successfully abstract (though maybe not in the cleanest way).",1,1,"I don't find exact duplication, but I do find many useless comments like:
```
# Set phoneme_count to the size of the phonemes array
phoneme_count = len(phonemes)
```
This comments are 'correct', but actually reduce readability by clogging up the file with useless info",4,2,"Quite frequent and, again, negatively impacts readability.",4,2,,5,,1,2,,1,4,,3,3,,4,,
12/18/2024 14:51:19,,Python,Yes,"ChatGPT, Gimini",,Master student,3-5 years,1,5,,3,5,Sometimes Even if I make it clear what it has to be taken into consideration later on but not  in the first prompt. chatgpt keep giving me the same error of the wrong Logic ,2,4,,5,,4,4,,4,3,,2,3,,3,4,,4,4,,4,,3,5,,3,3,,4,,3,2,,1,1,,4,2,,4,2,,3,,5,5,,1,5,,3,5,,4,,
12/18/2024 18:08:02,,"Python, JavaScript",Yes,"ChatGPT, GGUF models from HF","Memory is limited to a few hundred lines at most, and has difficulty remembering things throughout.",Just senior dev,More than 5 years,3,2,I don't depend on LLMs to generate correct logic.,3,2,I don't depend on LLMs to generate correct logic.,3,2,I don't depend on LLMs to generate correct logic.,2,I don't depend on LLMs to generate correct logic.,4,1,I don't depend on LLMs to generate correct logic.,4,1,I don't depend on LLMs to generate correct logic.,4,1,I don't depend on LLMs to generate correct logic.,4,1,I don't depend on LLMs to generate correct logic.,4,1,I don't depend on LLMs to generate correct logic.,1,,2,4,"I do find the LLM is better at coming up with naming than I am when it's given enough context, and I use it for that purpose often.  Sometimes I will 1-3 shot the LLM with further prompting to capture some distinction and it seems to find the right words well.  Sometimes it doesn't though and I'm left using my last best idea.",3,4,"I use LLMs often to help improve the readability of my code after it's written, and it quite often does provide effective readability improvements and other equivalent variants of functional code.  I've also had it document my code extensively.",5,,1,5,,1,4,,4,5,"The code digested by LLMs from other programmers often has shit branch logic, and it reflects that.  I often do find myself cleaning up these mistakes, and they're extremely expensive both for readability and performance (either at compile time or runtime it's still true)",4,5,,5,LLMs seem to be as bad as humans at switches and try/catch and other error handling blocks,5,3,"These always get caught in compilation, but I would rather it did this correctly because I want to focus on doing the logic not cleaning up the fluff.",3,2,,1,3,,4,,
12/18/2024 22:25:01,,Python,Yes,ChatGPT,Not correct answer most of the time,PhD,More than 5 years,2,2,"I used genAI, but not that often. ",2,2,,4,4,,4,,4,3,,4,3,,3,3,,2,2,,3,3,,4,,3,3,,5,3,,2,,3,3,,2,2,,3,3,,2,2,,2,,4,3,,2,2,,2,3,,3,,
12/19/2024 6:29:57,,"Python, GO, Bash",Yes,"ChatGPT, Codestral, Llama 3.1","Lack of context makes it difficult to provide an exact solution most of the times, solutions are usually basic (no advanced code features are used), LLMs usually find it difficult to write generalized code, hallucinations on less common functions/APIs",DevOps Engineer,3-5 years,2,5,"In my experience, providing specific inputs/outputs of a piece of code you want the LLM to generate results in the response being wrong most of the times. The model will focus ""too much"" on making your input-output relationships satisfied, while not providing a working function for any input-output combination",1,3,I believe among all the types of errors these are the easiest to catch,2,4,,4,,3,2,,4,2,"In my experience, ""guiding"" the LLM to an efficient solution can work. In general, however, one asks the LLM to give a solution, thus without knowing whether the provided one is optimal, making it impossible to guide the LLM. Notice that this can only be achieved if chatting with the LLM (not through code suggestions).",5,2,"Usually small impact, unless the extra steps add unnecessary time/memory complexity",4,1,,5,1,"I believe this to be the most common kind of mistake LLMs make; also, excuse my pettiness, but the largest divisor of a number `n` is at most `n/2` :)",2,,3,4,"Very common problem for Python: a lot of times, LLM solutions overwrite methods and functions from the standard library.",3,1,"If accompanied with an explaination, it does not bother me, personally. Can be extra ""surface"" for logic errors",1,,2,3,,1,1,,2,1,,2,1,,1,,2,3,,4,3,,2,5,,4,,
12/20/2024 12:19:09,,"JavaScript, GO",Yes,ChatGPT,"Function calls and imported package that not exists, not working code in general. ",Junior,1-3 years,3,5,,4,5,,2,4,,5,,4,3,,4,3,,5,4,,4,4,,4,4,,4,,5,5,,3,3,,4,,,4,,1,1,,4,4,,3,3,,4,,5,5,,3,5,,4,5,,5,,
12/20/2024 14:40:51,,"Python, Java, JavaScript",Yes,"Copilot, ChatGPT","The code generated by LLMs may not always be accurate, and debugging such code can sometimes be more time-consuming than writing it manually. Additionally, LLMs can experience contextual issues, such as forgetting the context of the conversation after a certain point, which necessitates the updating of their memory.",Software Engineer III,More than 5 years,2,2,,4,4,"Given my primary focus on LLM-generated boilerplate code, this issue is not particularly significant. Even partially implemented logic is superior to incorrect logic, as it is easier to write the missing piece than debug the incorrect logic.",2,3,,4,,4,4,"I have frequently encountered this issue while utilizing LLMs for development purposes. Primarily, I employ Copilot integrated with my IDE, which allows me to share my perspective. From this standpoint, I have observed instances where LLMs generate memory-inefficient code if the remaining portion of my code is not written in an efficient manner.",2,3,,4,2,,2,1,,4,3,,4,,4,4,"Nowadays, integrated development environments (IDEs) possess sufficient intelligence to identify these inconsistencies, rendering them a minor concern for me.",4,4,,4,,4,4,,2,1,,4,2,,2,2,,4,,4,3,,2,2,,4,3,,4,,
12/20/2024 19:57:17,,Python,Yes,ChatGPT,"Sometimes, the code is unnecessarily long or complex (for simple tasks). The code does not work or the change in code provided by the LLM to solve an exception/error does not work. Sometimes when I ask it to modify a small part, it modifies more than what I asked and it confuses me. What's more, sometimes I give it a sample code that works and ask it to modify it to my special use case and it does not use all parts of the sample code. ",PhD Student ,More than 5 years,1,5,I have not encountered it with ChatGPT. I don't think large LLMs actually make these mistakes very often.,3,5,It happens a lot for me when handling more complex regex patterns. Or when I ask it to handle complicated excel/google sheets formulas (if it is considered programming). Patterns in strings seem to be hard to elicit for ChatGPT at least.,2,4,,5,,1,4,I do not think I have seen that many or that I would catch all of them if I saw them.,1,4,Again I do not think I have seen that many or that I would catch all of them if I saw them.,3,3,,1,4,the relevance really depends on the use case. ,1,4,Again I do not think I have seen that many or that I would catch all of them if I saw them.,4,Sometimes there are functions created in the code that are not necessary. ,1,2,"I really do not think sum is confusing in the example above. And what is good about Chatgpt at least, is that the code comes with a lot of comments and textual explanations.",3,2,"Again what is good about Chatgpt at least, is that the code comes with a lot of comments and textual explanations. Or you can easily ask it to break down the confusing part for you. ",2,Sometimes it creates the code in different sections. I prefer the code to be provided entirely so I don't have to put sections together. I am afraid I might miss something.,1,4,I do not see it that often with Chatgpt If anything Chatgpt tends to do the exact opposite by abstracting everything away in separate functions. ,1,2,If they are repeated just twice that might not be important. But your example looks very bad. ,1,2,,1,2,,2,,1,3,,1,4,,2,5,I think sometimes it uses APIs that do not exist in the library.,4,,"Sometimes the inefficiency is not in the code itself but in how it is presented. Like I said in a section, the code is presented in separate sections with descriptions in between. Or sometimes when you ask it to modify one part, it modifies the other parts as well (because it is regenrating code) and I prefer to stick to the initial implementation. "
12/21/2024 15:48:15,,Python,Yes,ChatGPT,"Hallucinations, incomplete implementetions",Creative Solutions Consultant,3-5 years,3,4,,4,5,,3,4,,4,,2,3,,2,3,,2,3,,2,3,,1,2,,2,,3,3,,4,3,,4,,4,3,,2,1,,3,4,,2,3,,3,,2,3,,2,3,,3,4,,4,,
12/22/2024 23:06:10,,"Python, C/C++",Yes,ChatGPT,"Discontinuous programme logic, incorrect output formatting, forced naming conventions",Master's,More than 5 years,3,5,"When the LLM chain starts to encounter false logic, it is often not possible to guide it back to the right logic without retrying the whole chain with more detailed descriptions.",2,3,,4,2,,5,,2,3,,4,3,,1,1,,1,1,,4,2,,4,,5,4,It is frequently the case that the input instructions are unable to set every variable manually.,5,2,,3,,1,2,Haven't encounter this problem yet,1,1,Never encounter this,2,2,,1,2,,5,,3,1,Easy to debug,3,5,Sometimes comes with false logic.,1,5,,4,,
12/23/2024 0:00:35,,"Python, SQL",Yes,"ChatGPT, Claude","For data integration operations, even based on hints its hard to get code for aggregation operations like sum, average or count. LLM struggles to identify which operation to use until stated explicitly ",PhD,More than 5 years,2,2,"Wrong logic handling might  need explicit prompt handling, stating ""what not to do"" at all. ",4,3,Partially wrong logic can be handled with data profiling based hints. ,4,4,would be interested in knowing how these can be removed completely. ,4,None,2,3,Do not care much about memory issue in my work. ,1,4,,4,4,Usually manually remove them rather then interacting with LLM again.,2,2,,3,4,,4,,1,4,,3,2,Complex code is fine as long as it works. ,3,None,1,5,,4,5,Sometimes correct code is commented and left for user to select if user want to use that part. ,4,5,,2,5,,4,no,2,5,,1,5,,1,5,,5,,No.
12/24/2024 17:15:09,,"Python, JavaScript",Yes,"ChatGPT, phi3, phi3.5, qwen2.5-coder 7b, aider in combination with a local LLMs (note I mostly use small language models)","They will generate code that is not applicable to my current project, if you do not provide LLM enough details. 

If you provide everything about the codebase, all models, when asked to generate, for example an API, they start generating something that I a milkshake(not correct) of code, not the code I want.

If I provide the LLM that has a large context window with enough examples of what it can and needs to do, without providing the entire codebase, then I get good results when I ask the LLM to generate an API, and it does it even with a smaller LLM, like phi 3.5, or qwen2.5-coder. ",Web dev,More than 5 years,1,1,"Ignore my answer, I am skipping understanding the code in the image to find out what is wrong and thus I believe my answer isn't valid...",1,1,"Ignore my answer, I am skipping understanding the code in the image to find out what is wrong and thus I believe my answer isn't valid...",1,3,"Ignore my answer, I am skipping understanding the code in the image to find out what is wrong and thus I believe my answer isn't valid.",4,"Wrong Logic - in my tests was due to giving the model more data so it gets confused, or when not giving it enough data.

Partially Wrong Logic: - Yes, depending on the LLM the results might be better/worse.
Wrong Method Input:  - Yes, depending on the LLM the results might be better/worse",1,1,Ignore my answer,4,4,...,1,1,...,1,1,...,1,1,...,1,...,1,5,,2,3,,5,,2,1,,1,5,,4,1,,3,1,,3,,5,5,,4,5,,1,5,,5,,
12/25/2024 15:24:21,,Python,Yes,ChatGPT,hallucination,master's,3-5 years,1,2,wrong logic usually occurs when the prompt is not detailed enough to convey a clear idea of what we want to achieve through the LLM,4,4,,3,3,,5,no,3,3,"i think this can be solved once u ask for an optimised code in the prompt , but the LLM doesn't always provide it ",2,2,,2,2,,2,2,no,3,3,no,3,no,2,3,,3,3,,3,,2,2,,1,1,,2,2,,4,4,,2,,1,1,,1,1,,4,4,,3,,
12/26/2024 17:04:39,,Python,Yes,"Copilot, ChatGPT, Gemini","When generating code from scratch with LLMs, I have found a few different types of issues, such as logical errors (failure to properly understand logic requirements), inefficient code (for example, LLMs usually suggest nested loops when a more efficient algorithm would be needed), and lack of proper error handling.
Besides those, one of main issues is the lack of context. Maybe this is actually one of the root causes for issues, but LLMs often fail to generate a correct solution given that it lacks the proper context about the entire code or the business use case.",AI Applied Scientist,More than 5 years,4,5,,4,4,,1,5,"Although I haven't seen this particular issue many times, it is very relevant since it requires the developer to have deep knowledge about the underlying logic and proper usage of methods to avoid adopting the generated code blindly. The method might seem logically correct at first, but it can result in subtle, hard-to-detect errors if the developer does not closely inspect the generated code and the correctness of the implementation.",5,,4,3,"I think this type of error is relevant but not as much as logic errors. Here, the developer can easily identify the performance issues and optimize the code (even using LLM-assisted optimizations)",4,3,,3,3,,1,3,,1,4,,3,"Just one overall comment: personally, I find performance issues less relevant as logic issues overall. An inefficient but working solution is still better than a non-working solution (that might require much more debugging time). Inefficient solutions can always be optimized later.",1,2,"In my experience, this is not very relevant. I believe proper prompting and explanation of the issue being solved (with proper business context) is extremely helpful to avoid this kind of issue.",1,4,"Although I haven't seen this issue often, I believe it is very relevant since it rqeuires a lot of time to understand the generated code.",3,,2,3,,1,2,I have never seen this kind of issue but it seems to be a type of issue that small LLMs would generate.,2,2,,1,3,,3,,1,3,,1,3,,1,3,,3,,"One issue I've encountered often (but each time less and less) is Lack of Error Handling for basic operations, such as parsing a JSON object (which can easily throw an error due to malformed objects for example). Ideally, for operations for which we know issues can arise, we want to have proper error handling (e.g. try-except)"
1/5/2025 7:05:57,,Python,Yes,ChatGPT,,Data Scientist,More than 5 years,5,5,This happens to me very frequently but usually a small change to the prompt or a feedback clarifying what's needed fixes the issue. ,4,5,,3,4,,5,,4,3,"This usually happens when I provide feedback on the initial provided code (which could be optimal in terms of memory but have some incorrect logic), and then LLMs try to fix the issue while not making many changes to the code which eventually leads to a sub-optimal solution whether in terms of memory or time.",4,3,,4,3,,3,3,,4,3,,3,,1,3,"usually, the names used in the generated code are very long clarifying its purpose",4,4,,4,,2,4,,1,1,,4,3,can we consider this as sub-optimal in terms of time?,4,3,,3,,4,5,,4,5,,3,5,,5,,"(probably can be considered related to partial logic category?): Makeup function names that do not exist or mix between functions belonging to different libraries. This usually occurs when trying to wrap LLMs in custom functions (e.g., to use Gemini in code that is designed to use Azure OpenAI)  "
1/6/2025 11:32:53,,C/C++,Yes,Copilot,I frequently have to be very specific in my prompts.,Principal software engineer,More than 5 years,1,5,,1,5,,1,3,,5,,4,1,,5,2,,1,2,,2,3,,1,4,,3,,4,1,,2,5,,5,,1,5,,4,4,,1,3,,5,2,,4,,4,3,,2,5,,1,5,,5,,
1/6/2025 14:10:49,,"Python, Matlab",Yes,ChatGPT,especially in Matlab and for signal processing the code that was generated had many issues and was using functions from older version libraries. ,PhD student,More than 5 years,1,5,,1,4,,3,4,,2,,3,3,,2,3,,3,3,,2,2,,1,3,,3,,2,2,,2,5,,5,,2,2,,1,1,,1,2,,1,1,,2,,3,2,,1,3,,1,5,,4,,
1/6/2025 18:26:55,,Python,Yes,ChatGPT,"Issues in: Variable naming or missing variable, OOP architecture, comments ",Master's,1-3 years,3,4,,3,4,,3,3,,3,Nope,4,4,,3,2,,4,3,,4,4,,3,5,,4,,2,4,,4,5,,4,,2,4,,2,4,,2,4,,3,4,,4,,3,4,,3,4,,2,4,,4,,
1/6/2025 21:58:13,,"Python, Java, shell",Yes,ChatGPT,"It takes time writing prompts to provide LLM enough context, otherwise, it will produce either useless code or code that needs to change a lot to be use. ",PhD,More than 5 years,3,5,"If we use LLM for coding, we may avoid wrong logic by writing detailed prompts.",4,5,,1,2,,5,Some potential runtime bugs like denominator will be zero at certain situations.,2,2,"It depends on the extent of our application. If we just write a local script to process small data, it would be fine if the code is suboptimal in terms of memory.",2,5,It is a big issue if the code takes a lot of time to run.,1,1,,2,2,,3,5,,4,,2,2,,3,4,,3,,2,1,,3,3,,2,4,,4,4,,3,,2,5,,3,5,,1,5,,5,,Potential runtime bugs like I mentioned before.
1/6/2025 22:31:34,,Python,Yes,ChatGPT,"Code doesn't run properly in the first run, need to do debugging and back-and-forth modification with ChatGPT",PhD student,More than 5 years,1,5,ChatGPT very rarely makes this kind of extreme errors,2,4,,4,4,,4,"ChatGPT does make logic errors. Usually if I get some incorrect results when running the code, I can either correct the error by myself, or give the results to ChatGPT and ask it to revise the code again. I usually get the correct code within two or three iterations.",2,2,,2,2,,2,2,,2,2,,2,2,,2,,1,2,,1,2,,2,ChatGPT's code is usually much more readable than my code,3,1,,2,1,,1,1,,2,1,,1,Don't really care about this. And ChatGPT is usually much better in this than human programmers,2,2,Easy to fix,1,5,,1,5,,4,,
1/6/2025 22:47:06,,"Python, C/C++",Yes,"ChatGPT, claude","Sometimes the code written doesn't work directly and needs debugging, also sometimes the code is not optimised",Master's,More than 5 years,2,3,,4,4,,2,2,LLMs are good in defining the methods inputs,4,,4,4,if precised LLMs will succeed in generating memory efficient code,4,4,,4,4,,2,2,,2,2,,5,,1,1,,2,2,,2,,2,2,,1,1,,4,4,,5,5,,5,,3,3,,2,2,,1,1,,5,,
1/8/2025 7:28:30,,"Python, C/C++",Yes,Qwen2.5-Coder-32B-Instruct,LLM cannot get the whole picture of my project,Master candidate,1-3 years,1,2,,5,5,Often I come across with logic errors that need careful debugging. These logic errors are so delicate that sometimes I cannot realize them when adopting LLM's completion until I eventually run the whole code.,3,3,,5,,4,2,"Changing or improving is less important than implementing a feature. I would consider implementing a feature first, and then improve it.",3,2,Same as sub-optimal memory solution.,2,2,,2,2,,3,2,,2,,1,1,,1,1,,1,,3,2,,2,1,,3,2,,1,1,,2,,4,1,,3,2,,2,1,,2,,
1/8/2025 17:10:38,,Python,Yes,ChatGPT,Lack of accuracy ,Graduate student ,3-5 years,3,5,No,4,5,No,4,5,No,5,No,2,3,No,2,3,No,4,5,,3,4,,3,4,,4,,1,2,,2,4,,3,,1,3,,1,1,,2,1,,1,3,,2,,2,5,,1,5,,2,5,,3,,
1/8/2025 20:46:11,,Python,Yes,ChatGPT,,Mlops engineer,1-3 years,4,4,,3,4,,2,2,,4,,4,4,,3,4,,3,4,,2,2,,2,2,,2,,1,1,,1,1,,1,,1,1,,1,1,,3,3,,1,1,,2,,2,2,,1,1,,2,2,,2,,
1/8/2025 20:46:41,,Python,Yes,ChatGPT,,ML engineer ,3-5 years,3,2,,4,1,,2,5,,1,,1,4,,4,2,,3,2,,5,5,,2,4,,3,,4,2,,2,5,,4,,5,3,,3,2,,4,2,,1,3,,5,,2,3,,2,3,,4,2,,4,,
1/9/2025 16:24:00,,Python,Yes,"Copilot, ChatGPT","using random libraries, not following my coding style, confusing with long code snippets, hallucination",postdoctoral fellow,More than 5 years,2,3,,5,5,,5,5,,5,,2,5,,3,5,"usually the first one or two suggestions by Copilot are more efficient in term of complexity than the rest of its suggestion in a single round. When we force the model to generate diverse solution (higher temperature), it  increases the ratio of observing more inefficient solutions.",2,5,"I very rarely observed it as an output of high performance models (i.e. GPT4o), however it is important to be considered.",3,5,,5,5,,5,,2,4,,3,5,,5,,2,5,I didn't have this observation when working with stronger model in terms of performance and size,4,2,"It happens very often with Copilot when it wants to generate in place (cursor) suggestion or automatically complete the line of the code but when you deactive auto-completion on the setup, it goes away. It is more like an inefficacy of the tool than the model behind the tool.",1,2,,2,3,,4,,3,2,it can be fixed quickly with IDE properties.,4,5,,3,5,,5,,"there are other code block that could be interesting to consider such as a while loop that its condition never break or same scenario for recursive functions when there is no breaking condition, not using the same coding style as what we use in the workspace make the suggestions very inefficient to adapt with the workspace."
1/9/2025 17:07:08,,Python,Yes,"Copilot, ChatGPT","I used to use Copilot in my IDE but now it's been a while that I've disabled it because it would make stupid suggestions and distract me. I'd rather use chatGPT on demand, but sometimes it also generate buggy solutions and debugging takes longer than writing the code from scratch.",PhD,3-5 years,3,5,,4,5,,3,4,,5,,2,5,,1,4,,2,4,,1,3,,4,5,,5,,1,3,I chose the relatively low option because the developers can simply rename the names.,5,3,,4,,3,5,,1,2,,1,2,,1,2,,2,,1,4,,1,2,,1,3,,4,,
1/9/2025 22:26:54,,Python,Yes,ChatGPT,repetitive answers,Master's,More than 5 years,4,5,,3,5,,4,4,,5,,4,3,,4,4,,3,4,,2,4,,3,5,,5,,1,4,,5,4,,4,,1,4,,1,2,,3,4,,3,4,,4,,2,4,,2,5,,1,5,,5,,
1/10/2025 4:29:47,,Elixir,Yes,Copilot,"Usually it is pretty good, but something (maybe because it doesn't fully understand the context) the suggestions are irrelevant ",Senior Full Stack Developer,More than 5 years,2,2,,2,4,,4,4,,3,,2,3,,2,3,,4,3,,4,4,,4,3,,4,,2,4,,3,3,,4,,3,4,,3,5,,3,5,,3,5,,5,,2,4,,2,4,,4,5,,5,,
1/10/2025 6:01:56,,"Python, C/C++",Yes,"ChatGPT, Gemini","It can facilitate old methods or mix up programming language. Very often, more often than not actually, it writes a snippet of code in an older way and gets it right only after I tell it to modernize the code.","Lead Programmer, founder, CEO",More than 5 years,3,4,,4,2,,2,4,,4,,3,2,,2,2,,3,3,,2,4,,3,3,,4,,4,4,,3,3,,4,,3,4,,1,1,,2,2,,1,1,,4,,1,1,,1,1,,3,3,,3,,
1/10/2025 12:38:05,,"Python, Java",Yes,"Copilot, ChatGPT, Gemini, Mistral","I have encountered incomplete code generations, semantic errors that are sometimes difficult to identify, and occasional inability to generate code based on a specific version of the programming language.",Master's,More than 5 years,3,5,"I think that Wrong logic must be corrected to ensure that the program works as intended, avoids errors, protects data and maintains user confidence.",4,5,"It should be considered incomplete. Sometimes, it is not only incomplete but also important to determine how much code is missing to make it complete.",4,5,No,4,"It might be redundant logic. Sometimes, I keep getting the same output or the same error even after asking the LLM to address the issues.",3,4,I think exploring memory optimization could lead to better overall performance.,4,4,No,1,5,No,4,5,I think redundancy is a resource consumer and should be addressed as a major issue.,1,5,"I think dentifying time and memory inefficiencies is essential for optimizing performance. Focusing on improving time complexity and eliminating unnecessary steps can speed up execution, while optimizing memory usage guarantees resource efficiency, especially for large-scale applications.",5,"Maybe, Overuse of Recursion.",3,5,"I think it's good practice to use simple, concise, and descriptive naming.",4,5,"I think a code should be readable to make it easier for others (or the programmer) to understand, maintain, and debug in the future.",5,No,5,5,I think that duplication consumes too many compute resources and can lead to inefficiencies in performance and maintenance.,3,5,"I think comment duplication makes the readability ambiguous and can lead to confusion, making it harder to understand the code's intent.",4,5,"I think that any unnecessary elements should be addressed, as compute resources are valuable and should be managed efficiently.",1,5,No,5,No,5,5,"Most of the time, missing imports cause tests to fail or prevent the code from running properly.",3,5,"A missing variable declaration is like a car missing its front tires – it may start, but it won't function properly or may break down unexpectedly.",5,5,"I think it's normal, as syntax errors are very helpful during debugging by providing clear indications of where the issue lies.",5,No,"I might say Over (code) Generation, Sometimes, the LLM generates more than expected. The code may be correct, but it adds unnecessary lines of instructions."
1/10/2025 13:28:19,,"Python, Ruby",Yes,"Copilot, ChatGPT","Lack of knowledge on latest updates to the languages, frameworks, etc. Technology is moving fast and the LLMs are typically trained on older information.",Software Developer,1-3 years,2,2,,4,4,,2,2,,4,,4,4,,3,5,,4,4,,5,4,,5,4,,5,,3,2,,4,4,,3,,2,2,,1,1,,2,3,,2,3,,3,,4,3,,1,4,,2,4,,3,,
1/10/2025 16:11:59,,"Python, JavaScript",Yes,Claude,"Hallucinations in existing libraries and frameworks.
Inability to keep track of variable types especially when it comes to strong typed languages like TypeScript.
Inability to follow instructions when they require multiple dependecies",PhD,More than 5 years,3,4,,4,5,,2,3,,3,,4,3,,4,3,,5,3,,5,4,,3,2,,3,,2,4,,2,1,,3,,4,5,,1,1,,4,1,,3,1,,3,,5,3,,4,5,,4,5,,4,,
1/10/2025 16:34:10,,Python,Yes,ChatGPT,could not completely understand the tasks+ oversimplify the problems.,postdoc,More than 5 years,2,2,,4,4,,3,3,,4,,4,2,,3,2,,5,4,,4,3,,3,2,,2,,4,4,,3,3,,4,,4,4,,2,2,,5,5,,3,3,,4,,5,2,,4,4,,5,5,Actually I did not pay attention to the categories of errors when using the llms to generate codes. The answers may carry some biases and are based on my pure impression.,5,,
1/10/2025 16:34:15,,"Python, JavaScript",Yes,"ChatGPT, Gemini",inability to adapt to my pattern of coding,Bsc. Computer Science,1-3 years,1,5,"This question has 3 different interpretations - ""To Which extent Wrong Logic is relevant to be considered?""",2,5,"Likewise, this question has 3 different interpretations - ""To Which extent Partially Wrong Logic is relevant to be considered?""",2,5,,5,None at all,1,5,I think S-O-S would only happen when the request made to the llm is not explicit enough,1,5,,1,5,,1,5,,1,5,,5,None at all,1,5,,1,5,,5,None at all,1,5,,1,5,,1,5,,1,5,,5,,3,5,,1,5,,2,5,,5,,None at all
1/10/2025 18:26:46,,Python,Yes,ChatGPT,,PhD,More than 5 years,3,3,,4,3,,2,2,,3,,4,2,,3,2,,3,4,,3,4,,3,3,,3,,3,2,,2,3,,2,,3,2,,4,2,,3,3,,3,3,,3,,3,2,,2,4,,3,3,,3,,
1/11/2025 9:19:11,,Python,Yes,ChatGPT,Instruction's hallucination,Student(Ph.D),More than 5 years,2,5,,2,4,,3,3,A neutral answer. I didn't have such an issue.,4,No,2,4,No,3,4,,3,4,,3,4,,3,4,,4,,1,4,,3,4,,4,,3,4,,1,3,,1,4,,1,4,,4,,1,5,,1,4,,2,5,,4,,No
1/12/2025 4:34:46,,Python,Yes,ChatGPT,"LLM wrongly uses function/library in the context of what I ask, LLM fails to address the task at hand and reformulating the prompt does not seem to help etc.",PhD,3-5 years,3,2,"I get what you mean with Wrong Logic, but the example is not the best (i.e. just returning a constant), as it is a very specific use case that I personally rarely encounter. However, implementing a false logic is something that is more common. However, these are not too important for me, as when it is that wrong a mistake is easily notice and so I would just reprompt the LLM (or give up and do it myself)",4,3,"More frequent and a bit more important than previous category, as it can somehow deceive novice user. But, judging by the example, they are still enough different to know there is a mistake",5,4,"I have a bit of trouble seeing the difference with previous category but I guess it is a matter of degree of inexactitute. In that case, judging by the example, the mistake is very subtle and hard to notice by reading the code (but easier if testing it). So, I judge this category relatively to the two previous ones.",4,,3,2,"I m using mostly Python and for research works. In that case, I m not too concerned about memory usage and so I don't pay much attention to the memory used in the code written by LLM and I don't ask it for a solution with low memory usage. I would say it is somewhat frequent if you don't require the LLM to pay attention to this point, but not very umportant unless you are in particular memory intensive use case or with language specific issues (C for instance)",3,3,"Similarly to memory optimality, but time is more of a concern to me in the code I wrote, as some inefficiency can sometimes double/triple the time of my whole program. However, I rarely pay attention to the time inefficiency of what the LLM writes or query the LLM to have a solution in a precise complexity: if needed, I will optimize the code myself or ask the LLM precisely to optimize a part of the code I would see as time consuming",3,2,"I haven't observed much this behavior, but similarly to previous category, as long as it doesn't impact the time noticeably I won't pay attention to it or try to fix it.",4,2,"I think this is somewhat more frequent compared to the previous one (or maybe I noticed it more?). However, I rarely bother with those, as it does very little to impact the time complexity overall",3,2,Same as previous one,3,,3,3,"It's frequent enough that I notice it, but it generally does not impact my comprehension. It only starts getting an issue when the code is very large",3,2,"In my experience, LLM producing code like this will turn out to be false. So, generally, I will reprompt the model if I did not understand the code, so it's not much of a problem. If anything, instead of having single lines like this, it's more time consuming to have the invert: a 20 lines code for something two lines could have solved. In that case, you have to read the whole logic and realize one or two utility functions could have solved the same problem",2,,1,2,"To me, it's pretty rare, especially with newer LLMs. When it does happen, you spot it easily or you catch it during a test so not a problem.",1,1,"Getting rarer too, plus in that case it's more a problem of the LLM not managing to generate something (it is stuck in loop). So just reprompt",3,2,Happens often but not much of an issue,1,1,Never really seen it and it doesn't affect much my code so I don't pay attention to it,2,,3,2,"It is frequent that LLM assumes the libraries are imported. Not much of a problem, I will just import it myself",3,3,Quite frequent and can be annoying to track down in larger code ,3,2,"It is still surprisingly common, especially in longer code. But pretty easy to spot and fix",3,,
1/12/2025 20:53:28,,Python,Yes,ChatGPT,,PhD ,3-5 years,2,4,,3,5,,2,5,,4,,4,5,,2,3,,3,5,,3,5,,1,3,,5,,2,3,,2,2,,3,,3,5,,2,2,,3,2,,2,2,,3,,2,4,,3,4,,3,5,,5,,
1/13/2025 10:07:49,,"JavaScript, typescript",Yes,"Copilot, Mistral, Cloude","It is far better at design then at code generation that makes sense, and it very often does not understand the codebase",CTO,More than 5 years,2,3,I don't see it that often especially with newer models like Sonnet 3.5. Most of the time the model will generate something.,5,4,This can be mitigated with further prompting the model to explicitly state what you want. ,3,2,"For us that was rarely a real problem, as most of the tasks we are professionally doing are CRUD stuff where it is important for the code to be correct and secure rather then fast.",4,,3,1,,3,1,This is again a thing where if you see that the solution is sub-optimal (and you care about that) you will re-prompt for a different solution.,4,4,,4,4,,2,2,,3,,4,5,"this is a real problem that happens but renaming variables in most ide's is pretty simple (f2) for vscode, so it will only be a problem with linters and when you don't know what is happening. I still think this makes ai a bad teaching tool.",2,4,"Now this is something I don't see very often, but I think it is important. I have the feeling that code being hard to understand for humans often makes it hard to understand to LLMs. This makes it so that when the LLM generates unreadable code further code generations will not be as good. ",4,,5,2,I think the programmer should worry about such things and be responsible for fixing them.,3,5,"This was happening a lot with copilot, but when using Supermaven or Cursor this is no longer a problem.",1,1,,3,1,,4,,1,5,"This was also fixed by Cursor and Supermaven, although initially that was not a real problem because you would just ask the IDE to import it. What was worse was when the module needed to be installed first. ",1,3,I don't remember ever seeing that ,3,4,,5,,
1/13/2025 18:50:44,,"Python, Java",Yes,"Copilot, ChatGPT","unused parameters, package conflict (e.g., different part of the code is based on different versions of the same package like sklearn), wrong result ---Not often though",PhD,More than 5 years,2,2,,3,3,,5,3,,3,,2,2,,2,2,,3,2,,3,2,,4,2,,4,,1,1,,3,2,,2,,4,2,,1,2,,4,2,,2,2,,2,,1,1,,3,2,,1,1,,1,,
1/13/2025 21:34:39,,Python,Yes,ChatGPT,Some times wrong answer looking as allucination,PhD,1-3 years,1,1,No,1,1,No,1,1,No,2,No,3,4,No,2,3,No,3,3,No,2,2,,3,3,No,4,No,1,1,No,4,4,It lead to understanding confusion of code,3,,1,1,,1,1,,4,4,,1,1,,2,,1,1,,1,1,,5,5,,4,,"Alluscination, I mean something that not exist but the LLM returns it. "
1/15/2025 16:18:56,,"Python, JavaScript",Yes,"ChatGPT, Gemini",Misrepresentation of the logic when the idea is supplied to the prompt,PhD,1-3 years,3,5,,4,4,,4,4,,3,,3,4,,3,4,,2,2,,3,3,,2,2,,4,,1,4,,3,2,,3,,3,4,,2,2,,2,4,,2,4,,3,,2,3,,2,3,,3,2,,2,,
1/15/2025 22:11:42,,"Python, C/C++",Yes,"Copilot, ChatGPT",,Master's,3-5 years,2,5,,2,4,,3,3,,4,,2,3,,1,3,,3,4,,2,4,,2,5,,3,,3,5,,2,5,,5,,1,5,,1,3,,1,4,,1,4,,5,,4,5,,1,4,,1,5,,5,,
